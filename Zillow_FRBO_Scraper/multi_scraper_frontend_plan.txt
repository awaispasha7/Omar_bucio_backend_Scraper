=================================================================
    MULTI-SCRAPER FRONTEND ARCHITECTURE PLAN
=================================================================

PROJECT GOAL:
Create a unified Next.js frontend to display data from 4 different scrapers
(Zillow FRBO, Trulia, Red, and one more)

=================================================================
RECOMMENDED FOLDER STRUCTURE:
=================================================================

property-scrapers/              # Root project folder
│
├── scrapers/                   # All your Scrapy scrapers
│   ├── zillow_scraper_frbo/    # Your existing scraper
│   │   ├── zillow_scraper/
│   │   ├── input/
│   │   └── output/
│   │       └── Zillow_Data.csv
│   │
│   ├── trulia_scraper/
│   │   └── output/
│   │       └── Trulia_Data.csv
│   │
│   ├── red_scraper/
│   │   └── output/
│   │       └── Red_Data.csv
│   │
│   └── scraper_4/
│       └── output/
│           └── Scraper4_Data.csv
│
├── frontend/                   # Next.js frontend
│   ├── app/                    # Next.js 14+ App Router
│   │   ├── page.tsx           # Home/Dashboard
│   │   ├── layout.tsx         # Root layout (navbar here)
│   │   ├── zillow/
│   │   │   └── page.tsx       # Zillow listings
│   │   ├── trulia/
│   │   │   └── page.tsx       # Trulia listings
│   │   ├── red/
│   │   │   └── page.tsx       # Red listings
│   │   └── scraper4/
│   │       └── page.tsx       # Scraper 4 listings
│   │
│   ├── components/             # Reusable components
│   │   ├── Navbar.tsx
│   │   ├── PropertyCard.tsx   # Card for each listing
│   │   ├── OwnerInfo.tsx
│   │   └── SearchBar.tsx
│   │
│   ├── lib/                    # Utility functions
│   │   ├── csvParser.ts       # Parse CSV files
│   │   └── dataFetcher.ts     # Fetch data from CSVs
│   │
│   ├── public/                 # Static assets
│   │   └── data/              # COPY CSV files here
│   │       ├── zillow.csv
│   │       ├── trulia.csv
│   │       ├── red.csv
│   │       └── scraper4.csv
│   │
│   ├── package.json
│   └── next.config.js
│
└── README.md


=================================================================
WHY THIS STRUCTURE?
=================================================================

1. SEPARATION OF CONCERNS:
   - Scrapers stay independent in their own folders
   - Frontend is separate and doesn't interfere with scraper code
   - Easy to run scrapers independently

2. DATA FLOW:
   - Scrapers write to their own output/Data.csv files
   - Frontend reads from public/data/*.csv (copy CSVs there)
   - OR use a simple script to auto-copy new CSVs to frontend

3. SCALABILITY:
   - Easy to add more scrapers - just add a new folder
   - Easy to add more pages in frontend
   - Shared components (Navbar, PropertyCard) reduce duplicate code


=================================================================
IMPLEMENTATION STEPS:
=================================================================

STEP 1: CREATE THE STRUCTURE
   1. Create a new root folder: "property-scrapers"
   2. Create "scrapers" subfolder
   3. Move your existing scrapers into "scrapers/"
   4. Create "frontend" subfolder

STEP 2: SETUP NEXT.JS FRONTEND
   1. cd into "frontend" folder
   2. Run: npx create-next-app@latest .
      - Choose: Yes to TypeScript
      - Choose: Yes to Tailwind CSS
      - Choose: Yes to App Router
      - Choose: No to src/ directory
   3. Install dependencies: npm install papaparse (for CSV parsing)

STEP 3: COPY CSV DATA
   Create a batch script in the root folder: sync_data.bat
   
   Contents:
   @echo off
   xcopy "scrapers\zillow_scraper_frbo\output\Zillow_Data.csv" "frontend\public\data\zillow.csv" /Y
   xcopy "scrapers\trulia_scraper\output\Trulia_Data.csv" "frontend\public\data\trulia.csv" /Y
   xcopy "scrapers\red_scraper\output\Red_Data.csv" "frontend\public\data\red.csv" /Y
   echo Data synced successfully!

   Run this script after each scraper run to update frontend data.

STEP 4: BUILD THE FRONTEND
   Create these components in order:
   
   1. Navbar.tsx - with tabs for all scrapers
   2. PropertyCard.tsx - displays one listing (like in your images)
   3. Page for each scraper - reads CSV and displays cards
   4. OwnerInfo.tsx - shows owner details when clicked


=================================================================
DATA HANDLING OPTIONS:
=================================================================

OPTION A: CLIENT-SIDE (SIMPLER - RECOMMENDED FOR START)
   - Store CSVs in public/data/
   - Frontend reads CSV on page load using fetch()
   - Parse CSV using papaparse library
   - Display in cards

   Pros: Simple, no backend needed
   Cons: Large CSVs can be slow

OPTION B: SERVER-SIDE (MORE ROBUST)
   - Use Next.js API Routes
   - Read CSVs from scrapers/*/output/ directly
   - Parse server-side and send JSON to frontend
   - Can add filtering, search, pagination

   Pros: Better performance, can handle large datasets
   Cons: Slightly more complex

START WITH OPTION A, upgrade to B if needed.


=================================================================
NAVIGATION STRUCTURE:
=================================================================

Based on your images:

Navbar Tabs:
   - FSBO (Zillow FRBO)     → /zillow
   - Trulia                  → /trulia  
   - Red                     → /red
   - Addresses               → /scraper4
   - All Listings            → / (home - combines all)

Each page shows:
   - Title (e.g., "ForSaleByOwner Dashboard")
   - Search bar
   - Stats (total listings, last updated, status)
   - Grid of property cards
   - Each card has:
     * Address
     * Price, Beds, Baths, Sqft
     * "View Listing" button
     * "Owner Information" button
     * "Download Details" button


=================================================================
NEXT STEPS:
=================================================================

1. Decide if you want to create the new structure
2. I can help you:
   - Set up the Next.js project
   - Create the Navbar component
   - Create PropertyCard component
   - Build the first page (Zillow)
   - Then replicate for other scrapers

Would you like me to start implementing this plan?


=================================================================
QUICK START COMMANDS:
=================================================================

# Create the structure
mkdir property-scrapers
cd property-scrapers
mkdir scrapers frontend

# Move existing scraper
move "C:\Users\HomePC\Desktop\zillow_scraper frbo" scrapers\

# Setup Next.js
cd frontend
npx create-next-app@latest . --typescript --tailwind --app --no-src-dir
npm install papaparse @types/papaparse

# Create data folder
mkdir public\data

=================================================================
