scrapy : 2025-12-02 18:25:20 
[scrapy.utils.log] INFO: Scrapy 
2.12.0 started (bot: hotpads)
At line:1 char:1
+ scrapy crawl hotpads_scraper 
-s CLOSESPIDER_ITEMCOUNT=2 -L 
INFO 2>&1  ...
+ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~
    + CategoryInfo          : 
NotS    pecified: (2025-12-02 
18:2...     (bot: 
hotpads):String) [], Rem    
oteException
    + FullyQualifiedErrorId : 
Nati    veCommandError
 
2025-12-02 18:25:20 
[scrapy.utils.log] INFO: 
Versions: lxml 6.0.2.0, libxml2 
2.11.9, cssselect 1.3.0, parsel 
1.10.0, w3lib 2.3.1, Twisted 
25.5.0, Python 3.13.7 
(tags/v3.13.7:bcee1c3, Aug 14 
2025, 14:15:11) [MSC v.1944 64 
bit (AMD64)], pyOpenSSL 25.3.0 
(OpenSSL 3.5.3 16 Sep 2025), 
cryptography 46.0.0, Platform 
Windows-11-10.0.26100-SP0
2025-12-02 18:25:20 
[scrapy.addons] INFO: Enabled 
addons:
[]
2025-12-02 18:25:20 
[py.warnings] WARNING: C:\Users\H
omePC\AppData\Local\Programs\Pyth
on\Python313\Lib\site-packages\sc
rapy\utils\request.py:120: 
ScrapyDeprecationWarning: 'REQUES
T_FINGERPRINTER_IMPLEMENTATION' 
is a deprecated setting.
It will be removed in a future 
version of Scrapy.
  return cls(crawler)

2025-12-02 18:25:20 
[scrapy.extensions.telnet] INFO: 
Telnet Password: b09ea92df54434da
2025-12-02 18:25:20 
[scrapy.middleware] INFO: 
Enabled extensions:
['scrapy.extensions.corestats.Cor
eStats',
 'scrapy.extensions.telnet.Telnet
Console',
 'scrapy.extensions.closespider.C
loseSpider',
 'scrapy.extensions.feedexport.Fe
edExporter',
 'scrapy.extensions.logstats.LogS
tats']
2025-12-02 18:25:20 
[scrapy.crawler] INFO: 
Overridden settings:
{'BOT_NAME': 'hotpads',
 'CLOSESPIDER_ITEMCOUNT': '2',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 0.5,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 
'hotpads.spiders',
 'REQUEST_FINGERPRINTER_CLASS': '
scrapy_zyte_api.ScrapyZyteAPIRequ
estFingerprinter',
 'REQUEST_FINGERPRINTER_IMPLEMENT
ATION': '2.7',
 'RETRY_HTTP_CODES': [412, 404, 
429, 520, 500, 502, 503, 504, 
522, 524, 520],
 'SPIDER_MODULES': 
['hotpads.spiders'],
 'TWISTED_REACTOR': 'twisted.inte
rnet.asyncioreactor.AsyncioSelect
orReactor'}
2025-12-02 18:25:20 
[scrapy_zyte_api.handler] INFO: 
Using a Zyte API key starting 
with 'e4e9688'
2025-12-02 18:25:20 
[scrapy_zyte_api.handler] INFO: 
Using a Zyte API key starting 
with 'e4e9688'
2025-12-02 18:25:20 
[scrapy.middleware] INFO: 
Enabled downloader middlewares:
['scrapy.downloadermiddlewares.of
fsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.ht
tpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.do
wnloadtimeout.DownloadTimeoutMidd
leware',
 'scrapy.downloadermiddlewares.de
faultheaders.DefaultHeadersMiddle
ware',
 'scrapy.downloadermiddlewares.us
eragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.re
try.RetryMiddleware',
 'scrapy.downloadermiddlewares.re
direct.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.ht
tpcompression.HttpCompressionMidd
leware',
 'scrapy.downloadermiddlewares.re
direct.RedirectMiddleware',
 'scrapy.downloadermiddlewares.co
okies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.ht
tpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.st
ats.DownloaderStats',
 'scrapy_zyte_api.ScrapyZyteAPIDo
wnloaderMiddleware']
2025-12-02 18:25:20 
[scrapy.middleware] INFO: 
Enabled spider middlewares:
['scrapy.spidermiddlewares.httper
ror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.refere
r.RefererMiddleware',
 'scrapy.spidermiddlewares.urllen
gth.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.
DepthMiddleware']
2025-12-02 18:25:21 
[scrapy.middleware] INFO: 
Enabled item pipelines:
['hotpads.pipelines.HotpadsPipeli
ne']
2025-12-02 18:25:21 
[scrapy.core.engine] INFO: 
Spider opened
2025-12-02 18:25:22 
[hotpads_scraper] INFO: Supabase 
client initialized
2025-12-02 18:25:22 
[scrapy.extensions.logstats] 
INFO: Crawled 0 pages (at 0 
pages/min), scraped 0 items (at 
0 items/min)
2025-12-02 18:25:22 
[scrapy.extensions.telnet] INFO: 
Telnet console listening on 
127.0.0.1:6023
2025-12-02 18:25:27 
[hotpads_scraper] INFO: Found 1 
location(s) to scrape
2025-12-02 18:25:27 
[hotpads_scraper] INFO: Starting 
scrape for: chicago IL (https://h
otpads.com/chicago-il/apartments-
for-rent)
2025-12-02 18:25:29 
[hotpads_scraper] INFO: Parsing 
response from: https://hotpads.co
m/chicago-il/apartments-for-rent
2025-12-02 18:25:29 
[hotpads_scraper] ERROR: Error 
parsing JSON-LD: Response 
content isn't text
2025-12-02 18:25:29 
[hotpads_scraper] INFO: JSON-LD 
yielded no URLs, trying XPath 
selectors...
2025-12-02 18:25:29 
[scrapy.core.scraper] ERROR: 
Spider error processing <GET http
s://hotpads.com/chicago-il/apartm
ents-for-rent> (referer: None)
Traceback (most recent call 
last):
  File "C:\Users\HomePC\AppData\L
ocal\Programs\Python\Python313\Li
b\site-packages\scrapy\utils\defe
r.py", line 327, in iter_errback
    yield next(it)
          ~~~~^^^^
  File "C:\Users\HomePC\AppData\L
ocal\Programs\Python\Python313\Li
b\site-packages\scrapy\utils\pyth
on.py", line 368, in __next__
    return next(self.data)
  File "C:\Users\HomePC\AppData\L
ocal\Programs\Python\Python313\Li
b\site-packages\scrapy\utils\pyth
on.py", line 368, in __next__
    return next(self.data)
  File "C:\Users\HomePC\AppData\L
ocal\Programs\Python\Python313\Li
b\site-packages\scrapy\core\spide
rmw.py", line 106, in 
process_sync
    yield from iterable
  File "C:\Users\HomePC\AppData\L
ocal\Programs\Python\Python313\Li
b\site-packages\scrapy\spidermidd
lewares\referer.py", line 379, 
in <genexpr>
    return (self._set_referer(r, 
response) for r in result)
                                 
                   ^^^^^^
  File "C:\Users\HomePC\AppData\L
ocal\Programs\Python\Python313\Li
b\site-packages\scrapy\core\spide
rmw.py", line 106, in 
process_sync
    yield from iterable
  File "C:\Users\HomePC\AppData\L
ocal\Programs\Python\Python313\Li
b\site-packages\scrapy\spidermidd
lewares\urllength.py", line 57, 
in <genexpr>
    return (r for r in result if 
self._filter(r, spider))
                       ^^^^^^
  File "C:\Users\HomePC\AppData\L
ocal\Programs\Python\Python313\Li
b\site-packages\scrapy\core\spide
rmw.py", line 106, in 
process_sync
    yield from iterable
  File "C:\Users\HomePC\AppData\L
ocal\Programs\Python\Python313\Li
b\site-packages\scrapy\spidermidd
lewares\depth.py", line 54, in 
<genexpr>
    return (r for r in result if 
self._filter(r, response, 
spider))
                       ^^^^^^
  File "C:\Users\HomePC\AppData\L
ocal\Programs\Python\Python313\Li
b\site-packages\scrapy\core\spide
rmw.py", line 106, in 
process_sync
    yield from iterable
  File "C:\Users\HomePC\Desktop\H
otpads_Scraper\hotpads\spiders\ho
tpads_scraper.py", line 122, in 
parse
    records = response.xpath("//l
i[contains(@class, 
'styles__li')]")
  File "C:\Users\HomePC\AppData\L
ocal\Programs\Python\Python313\Li
b\site-packages\scrapy\http\respo
nse\__init__.py", line 182, in 
xpath
    raise NotSupported("Response 
content isn't text")
scrapy.exceptions.NotSupported: 
Response content isn't text
2025-12-02 18:25:29 
[scrapy.core.engine] INFO: 
Closing spider (finished)
2025-12-02 18:25:29 
[scrapy.extensions.feedexport] 
INFO: Stored csv feed (0 items) 
in: output/Hotpads_Data.csv
2025-12-02 18:25:29 
[scrapy.statscollectors] INFO: 
Dumping Scrapy stats:
{'downloader/request_bytes': 635,
 'downloader/request_count': 1,
 'downloader/request_method_count
/GET': 1,
 'downloader/response_bytes': 
632169,
 'downloader/response_count': 1,
 'downloader/response_status_coun
t/200': 1,
 'elapsed_time_seconds': 
7.480339,
 'feedexport/success_count/FileFe
edStorage': 1,
 'finish_reason': 'finished',
 'finish_time': 
datetime.datetime(2025, 12, 2, 
13, 25, 29, 588452, 
tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/ERROR': 2,
 'log_count/INFO': 18,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'scrapy-zyte-api/429': 0,
 'scrapy-zyte-api/attempts': 1,
 'scrapy-zyte-api/error_ratio': 
0.0,
 'scrapy-zyte-api/errors': 0,
 'scrapy-zyte-api/fatal_errors': 
0,
 'scrapy-zyte-api/mean_connection
_seconds': 1.5146749999839813,
 'scrapy-zyte-api/mean_response_s
econds': 2.3422254999168217,
 'scrapy-zyte-api/processed': 1,
 'scrapy-zyte-api/request_args/ht
tpResponseBody': 1,
 'scrapy-zyte-api/request_args/ur
l': 1,
 'scrapy-zyte-api/status_codes/20
0': 1,
 'scrapy-zyte-api/success': 1,
 
'scrapy-zyte-api/success_ratio': 
1.0,
 'scrapy-zyte-api/throttle_ratio'
: 0.0,
 'spider_exceptions/NotSupported'
: 1,
 'start_time': 
datetime.datetime(2025, 12, 2, 
13, 25, 22, 108113, 
tzinfo=datetime.timezone.utc)}
2025-12-02 18:25:29 
[scrapy.core.engine] INFO: 
Spider closed (finished)
